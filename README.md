# bigdata-storage-lab-<Sorzano>

## üß™ Laboratorio T√©cnico: "De CSVs heterog√©neos a un almac√©n anal√≠tico confiable"

### üéØ Objetivo

El prop√≥sito de este laboratorio es construir un flujo de procesamiento de datos que tome archivos CSV heterog√©neos como fuente, y los transforme en un almac√©n anal√≠tico robusto, trazable y de calidad. El flujo incluir√° las siguientes etapas clave:

1. **Ingesta** de archivos CSV provenientes de diversas fuentes (estructura, codificaci√≥n, esquema, etc.).
2. **Validaci√≥n de calidad**: detecci√≥n de errores estructurales, tipos incorrectos, valores faltantes y duplicados.
3. **Normalizaci√≥n de datos**: unificaci√≥n de formatos, tipos y esquemas para facilitar su an√°lisis posterior.
4. **Almacenamiento en capas**:
   - **Bronze**: datos crudos (raw) sin procesar, tal como fueron ingeridos.
   - **Silver**: datos limpios, validados y normalizados, listos para an√°lisis.
5. **Exposici√≥n de KPIs** a trav√©s de una aplicaci√≥n interactiva usando **Streamlit**, conectada a la capa Silver.

---

### üì¶ Entregables

1. **Repositorio p√∫blico en GitHub** (`bigdata-storage-lab-<apellido>`) que contenga:
   - C√≥digo fuente (scripts de ingesta, validaci√≥n, transformaci√≥n y carga).
   - Archivos de configuraci√≥n.
   - Carpeta `docs/` con documentaci√≥n t√©cnica.
   - Carpeta `notebooks/` opcional para exploraciones o prototipos.
   - README bien estructurado con instrucciones de uso.
2. **Aplicaci√≥n Streamlit** con visualizaci√≥n de KPIs clave derivados de los datos normalizados.
   - KPIs sugeridos: % de registros v√°lidos, evoluci√≥n temporal de datos, top entidades (clientes, productos, etc.).
   - Permitir filtrado b√°sico y visualizaciones din√°micas.

---

### ‚úÖ Criterios de Evaluaci√≥n

| Criterio                         | Detalles                                                                 |
|----------------------------------|--------------------------------------------------------------------------|
| **Dise√±o y justificaci√≥n t√©cnica** | Claridad en la arquitectura del pipeline, elecci√≥n de tecnolog√≠as, modularidad del c√≥digo. |
| **Calidad de datos**             | Nivel de limpieza y validaci√≥n implementado, manejo de casos extremos, cobertura de reglas de negocio. |
| **Trazabilidad y modelado DW**   | Organizaci√≥n en capas (bronze/silver), naming conventions, manejo de metadata y logs. |
| **Documentaci√≥n**                | README completo, diagramas si aplica, instrucciones reproducibles, comentarios en el c√≥digo. |
| **Uso adecuado de Streamlit**    | UX b√°sica pero funcional, filtros √∫tiles, KPIs relevantes, conexi√≥n efectiva a datos silver. |

---

### ‚ö†Ô∏è Qu√© NO subir

- üö´ Archivos que contengan **datos personales, sensibles o confidenciales**.
- üö´ Claves API, contrase√±as o tokens en texto plano.
- üö´ Archivos binarios innecesarios (.zip, .pyc, .exe, etc.).
- üö´ Bases de datos completas (solo samples si son necesarias).

Usa archivos de ejemplo anonimizados o generados sint√©ticamente para pruebas.

---

### ‚è±Ô∏è Tiempo Estimado por Fase

| Fase                             | Tiempo estimado         |
|----------------------------------|--------------------------|
| Ingesta de CSVs                 | 0.5 d√≠as (4 horas)       |
| Validaci√≥n y profiling          | 1 d√≠a                    |
| Normalizaci√≥n + capa Bronze     | 1 d√≠a                    |
| Generaci√≥n de capa Silver       | 1 d√≠a                    |
| Desarrollo de KPIs y Streamlit  | 1.5 d√≠as                 |
| Documentaci√≥n y revisi√≥n final  | 0.5 d√≠as (4 horas)       |
| **Total estimado**              | **5.5 d√≠as (~44 horas)** |

---

### üöÄ ¬°A trabajar!

Este laboratorio simula un caso real de trabajo con datos desordenados y la necesidad de construir confianza en ellos a trav√©s de un pipeline moderno. Usa las herramientas con las que te sientas m√°s c√≥modo: `pandas`, `pyarrow`, `duckdb`, `pyspark`, `dbt`, etc. Lo importante es **la calidad del flujo y la claridad del resultado**.

> Para cualquier duda t√©cnica, consulta los issues del repo o pregunta a tu instructor.

---
